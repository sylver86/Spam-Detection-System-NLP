{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sylver86/Spam-Detection-System-NLP/blob/main/Progetto_Spam_Filter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae817f75-5cc5-4e0c-b154-59a0f6eeb93e",
      "metadata": {
        "id": "ae817f75-5cc5-4e0c-b154-59a0f6eeb93e"
      },
      "source": [
        "# Progetto : Sistema di Spam Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fde595f-a921-4c27-9f21-b24041c25909",
      "metadata": {
        "id": "9fde595f-a921-4c27-9f21-b24041c25909"
      },
      "source": [
        "## Panoramica del Progetto\n",
        "\n",
        "L'obiettivo di questo progetto è creare una libreria Python capace di analizzare le email ricevute. La libreria fornirà funzionalità per classificare le email come SPAM o NON SPAM, identificare i principali argomenti tra le email SPAM, calcolare la distanza semantica tra questi argomenti ed estrarre le organizzazioni menzionate nelle email NON SPAM.\n",
        "\n",
        "### Obiettivi\n",
        "\n",
        "1. **Addestrare un Classificatore per Identificare le Email SPAM**\n",
        "   - Utilizzare il dataset fornito per addestrare un modello di machine learning in grado di classificare accuratamente le email come SPAM o NON SPAM.\n",
        "   - Valutare le prestazioni del classificatore utilizzando metriche standard come accuratezza, precisione, recall e F1-score.\n",
        "\n",
        "2. **Individuare i Principali Argomenti tra le Email SPAM**\n",
        "   - Effettuare il topic modeling sulle email SPAM per scoprire i principali temi o argomenti presenti.\n",
        "   - Utilizzare tecniche come la Latent Dirichlet Allocation (LDA) o la Non-negative Matrix Factorization (NMF) per l'estrazione degli argomenti.\n",
        "\n",
        "3. **Calcolare la Distanza Semantica tra gli Argomenti**\n",
        "   - Misurare la distanza semantica tra gli argomenti individuati per comprendere l'eterogeneità degli stessi.\n",
        "   - Applicare metriche come la Similarità Coseno o la Distanza di Jaccard per valutare la differenza tra i temi.\n",
        "\n",
        "4. **Estrarre le Organizzazioni dalle Email NON SPAM**\n",
        "   - Utilizzare tecniche di Named Entity Recognition (NER) per identificare e estrarre i nomi delle organizzazioni menzionate nelle email NON SPAM.\n",
        "   - Valutare l'accuratezza dell'estrazione confrontando i risultati con un set di dati annotato manualmente.\n",
        "\n",
        "### Struttura del Progetto\n",
        "\n",
        "1. **Preprocessing dei Dati**\n",
        "   - Pulizia del dataset e preparazione dei dati per il training del modello.\n",
        "   - Normalizzazione del testo, rimozione di stop words, tokenizzazione e stemming/lemmatizzazione.\n",
        "\n",
        "2. **Addestramento del Classificatore**\n",
        "   - Sperimentazione con diversi algoritmi di machine learning (es. Naive Bayes, Support Vector Machines, Random Forest, o reti neurali).\n",
        "   - Ottimizzazione degli iperparametri e valutazione del modello migliore.\n",
        "\n",
        "3. **Topic Modeling**\n",
        "   - Applicazione di LDA o NMF per identificare i principali argomenti nelle email SPAM.\n",
        "   - Interpretazione dei risultati e visualizzazione degli argomenti.\n",
        "\n",
        "4. **Calcolo della Distanza Semantica**\n",
        "   - Implementazione di metodi per calcolare la distanza semantica tra i vari argomenti.\n",
        "   - Analisi dell'eterogeneità degli argomenti identificati.\n",
        "\n",
        "5. **Named Entity Recognition**\n",
        "   - Utilizzo di librerie come spaCy o NLTK per estrarre le organizzazioni dalle email NON SPAM.\n",
        "   - Valutazione dell'accuratezza dell'estrazione tramite confronto con un set di dati di riferimento.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "109434eb-8a7a-40b7-9be3-231ed14a7146",
      "metadata": {
        "id": "109434eb-8a7a-40b7-9be3-231ed14a7146"
      },
      "source": [
        "## Preprocessing dei Dati"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06e8b442-d92a-4ad5-a16b-12dfe4a32cca",
      "metadata": {
        "id": "06e8b442-d92a-4ad5-a16b-12dfe4a32cca"
      },
      "source": [
        "Iniziamo a vedere il dataset per l'avvio delle procedure di pre-processing dei dati."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "0669e160-69b2-4b23-8262-e4c348cb0110",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "0669e160-69b2-4b23-8262-e4c348cb0110",
        "outputId": "bf5dc089-77ed-4d19-af1f-b3d908cd3ee7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0 label                                               text  \\\n",
              "0            605   ham  Subject: enron methanol ; meter # : 988291\\nth...   \n",
              "1           2349   ham  Subject: hpl nom for january 9 , 2001\\n( see a...   \n",
              "2           3624   ham  Subject: neon retreat\\nho ho ho , we ' re arou...   \n",
              "3           4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
              "4           2030   ham  Subject: re : indian springs\\nthis deal is to ...   \n",
              "...          ...   ...                                                ...   \n",
              "5166        1518   ham  Subject: put the 10 on the ft\\nthe transport v...   \n",
              "5167         404   ham  Subject: 3 / 4 / 2000 and following noms\\nhpl ...   \n",
              "5168        2933   ham  Subject: calpine daily gas nomination\\n>\\n>\\nj...   \n",
              "5169        1409   ham  Subject: industrial worksheets for august 2000...   \n",
              "5170        4807  spam  Subject: important online banking alert\\ndear ...   \n",
              "\n",
              "      label_num  \n",
              "0             0  \n",
              "1             0  \n",
              "2             0  \n",
              "3             1  \n",
              "4             0  \n",
              "...         ...  \n",
              "5166          0  \n",
              "5167          0  \n",
              "5168          0  \n",
              "5169          0  \n",
              "5170          1  \n",
              "\n",
              "[5171 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0457186a-3fc2-45b0-999d-49e252a792df\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>label_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>605</td>\n",
              "      <td>ham</td>\n",
              "      <td>Subject: enron methanol ; meter # : 988291\\nth...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2349</td>\n",
              "      <td>ham</td>\n",
              "      <td>Subject: hpl nom for january 9 , 2001\\n( see a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3624</td>\n",
              "      <td>ham</td>\n",
              "      <td>Subject: neon retreat\\nho ho ho , we ' re arou...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4685</td>\n",
              "      <td>spam</td>\n",
              "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2030</td>\n",
              "      <td>ham</td>\n",
              "      <td>Subject: re : indian springs\\nthis deal is to ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5166</th>\n",
              "      <td>1518</td>\n",
              "      <td>ham</td>\n",
              "      <td>Subject: put the 10 on the ft\\nthe transport v...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5167</th>\n",
              "      <td>404</td>\n",
              "      <td>ham</td>\n",
              "      <td>Subject: 3 / 4 / 2000 and following noms\\nhpl ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5168</th>\n",
              "      <td>2933</td>\n",
              "      <td>ham</td>\n",
              "      <td>Subject: calpine daily gas nomination\\n&gt;\\n&gt;\\nj...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5169</th>\n",
              "      <td>1409</td>\n",
              "      <td>ham</td>\n",
              "      <td>Subject: industrial worksheets for august 2000...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5170</th>\n",
              "      <td>4807</td>\n",
              "      <td>spam</td>\n",
              "      <td>Subject: important online banking alert\\ndear ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5171 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0457186a-3fc2-45b0-999d-49e252a792df')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0457186a-3fc2-45b0-999d-49e252a792df button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0457186a-3fc2-45b0-999d-49e252a792df');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fe6fc76d-0f0f-4bdc-af78-7902139c342e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fe6fc76d-0f0f-4bdc-af78-7902139c342e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fe6fc76d-0f0f-4bdc-af78-7902139c342e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5171,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1492,\n        \"min\": 0,\n        \"max\": 5170,\n        \"num_unique_values\": 5171,\n        \"samples\": [\n          2924,\n          3839,\n          3078\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4993,\n        \"samples\": [\n          \"Subject: hpl / conoco - teco waha 03 / 23 / 01 purchase\\ndaren , conoco invoiced hpl at $ 5 . 87 for 03 / 23 at pgev / waha and deal ticket 685350 shows $ 4 . 87 . can you confirm the price ? thanks .\",\n          \"Subject: holiday on - call data\\npipeline contact phone fax pager\\nblack marlin blair lichentwalter 713 853 - 7367 713 646 - 3201 ( h )\\n281 370 - 1866\\ndebbie thompson 713 853 - 3144 713 646 - 3201\\n( noms due today for 23 rd through 27 th )\\nchannel jim tobacco 713 420 - 2159\\ngas control 1 505 599 - 2333\\n( open thursday . noms will be due through monday )\\ncentana william spekels 713 627 - 6290 713 762 - 3450\\ndonna spencer 713 627 - 6255\\ngas control 1 888 204 - 1718\\n( noms due today for 23 rd through 27 th )\\nduke energy annette anderson 713 260 - 8603 713 949 - 3026\\n( on call ) bob moseman 713 - 260 - 8698 ( thursday )\\nopen tomorrow - noms will be due thru the 27 th )\\nlonestar gary gafford 214 670 - 2674 214 875 - 3810\\ngas control 214 875 - 2455 or 2456\\n( noms due today , 23 rd thru 27 th )\\nnorthern natural ben markey 853 - 7581 cell 713 446 - 9404 800 931 - 0398\\n( on call ) charlie mosey 853 - 1520\\ngas control 853 -\\n( open thursday - noms due thru 27 th . )\\neast trans - east texas\\ntejas gas control 713 767 - 5366\\npaula svehla 713 230 - 3569\\nmickey chapman 713 230 - 3546\\n( open thursday - noms due thru 27 th )\\nmidcon ( y 2 k ) ken nachlinger 713 369 - 9284 713 369 - 9375 888 733 - 5954\\n( on call ) steven 888 790 - 0255\\n( y 2 k ) don 888 733 - 4602\\ngas control 713 369 - 9200\\n( noms due today , 23 rd thru 27 th )\\nmoss bluff no current business\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label_num\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Ignora le righe corrotte\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/sylver86/Spam-Detection-System-NLP/main/spam_dataset_.csv\", on_bad_lines='skip')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfc30a59-4efc-4a4a-9cf9-c1c5dd8edffe",
      "metadata": {
        "id": "bfc30a59-4efc-4a4a-9cf9-c1c5dd8edffe"
      },
      "source": [
        "Come possiamo vedere alcuni testi riportano etichettatura 0 altri 1 a seconda se il testo viene classificato come spam o meno."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1bd405c-80ef-45ae-abea-f7d693004a91",
      "metadata": {
        "id": "f1bd405c-80ef-45ae-abea-f7d693004a91"
      },
      "source": [
        "Stiamo parlando quindi di creare un classificatore binario supervisionato."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a630350-b49c-45bb-82dd-731e33b560b8",
      "metadata": {
        "id": "2a630350-b49c-45bb-82dd-731e33b560b8"
      },
      "source": [
        "Iniziamo a pulire il testo attraverso le seguenti attività di Data Cleaning:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71bd632c-e086-42bc-b579-5afa4605154a",
      "metadata": {
        "id": "71bd632c-e086-42bc-b579-5afa4605154a"
      },
      "source": [
        "1. Lowercase\n",
        "2. Rimozione punteggiatura\n",
        "3. Lemmatizzazione\n",
        "4. Rimozione Stop words\n",
        "5. Rimozione numeri e spazi multipli"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61aaacc5-d2c5-4f04-b422-1dbaaab07fad",
      "metadata": {
        "id": "61aaacc5-d2c5-4f04-b422-1dbaaab07fad"
      },
      "source": [
        "Per far questo andiamo a crearci un metodo di pulizia sotto riportato utilizzando il modello in inglese dal momento che il testo contenuto in analisi è in lingua inglese:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "cc04e14a-e265-4d11-8ee9-facdcbe6a7cc",
      "metadata": {
        "id": "cc04e14a-e265-4d11-8ee9-facdcbe6a7cc"
      },
      "outputs": [],
      "source": [
        "english_stopwords = stopwords.words('english')\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "punctuaction = set(string.punctuation) #con il set evitiamo ripetizioni\n",
        "\n",
        "def data_cleaner(sentence):\n",
        "        sentence = sentence.lower() # Effettuiamo un lowercase della frase\n",
        "        for c in string.punctuation:\n",
        "            sentence = sentence.replace(c, \" \") # Rimuoviamo la punteggiatura\n",
        "        document = nlp(sentence)\n",
        "        sentence = ' '.join(token.lemma_ for token in document) # Effettuiamo la lemmatizzazione\n",
        "        sentence = ' '.join(word for word in sentence.split() if word not in english_stopwords) #Effettuiamo la rimozione stopwords\n",
        "        sentence = re.sub('\\d','',sentence) # Eliminiamo eventuali numeri\n",
        "        return sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31923fe5-ab5a-4452-8a36-3476aa242918",
      "metadata": {
        "id": "31923fe5-ab5a-4452-8a36-3476aa242918"
      },
      "source": [
        "Eseguiamo dunque tale processo per tutto il dataset andando ad aggiornare la colonna \"text\":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cdba35a-0661-42e0-8e62-4ddc51ea4b74",
      "metadata": {
        "id": "5cdba35a-0661-42e0-8e62-4ddc51ea4b74"
      },
      "outputs": [],
      "source": [
        "df['text_cleaning'] = df['text'].apply(data_cleaner)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3d75ace-ae3b-4df1-88fe-07d945cc2e88",
      "metadata": {
        "id": "b3d75ace-ae3b-4df1-88fe-07d945cc2e88"
      },
      "source": [
        "Verifichiamo la nuova colonna quale output mostrerà in seguito all'attività di DataCleaning che abbiamo appena effettuato."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23cb35fa-1c2a-440d-a7bd-0ff94165c8bb",
      "metadata": {
        "id": "23cb35fa-1c2a-440d-a7bd-0ff94165c8bb"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9936018-2d3b-4969-9456-3aa30d839a26",
      "metadata": {
        "id": "e9936018-2d3b-4969-9456-3aa30d839a26"
      },
      "source": [
        "## Addestramento di un Classificatore"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d000a8b6-0c7c-4c8d-b575-babbce13e4b5",
      "metadata": {
        "id": "d000a8b6-0c7c-4c8d-b575-babbce13e4b5"
      },
      "source": [
        "Ora che il Dataset è pronto andremo a valutare alcuni classificatori per poi scegliere il migliore in termini di performance e quindi di metriche."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ad9a933-2b88-44d2-8558-06f77fc3cc39",
      "metadata": {
        "id": "7ad9a933-2b88-44d2-8558-06f77fc3cc39"
      },
      "source": [
        "Iniziamo a dividere la parte di train da quella di test con :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d1c405c-e8d2-48c1-bb1a-93f112790898",
      "metadata": {
        "id": "5d1c405c-e8d2-48c1-bb1a-93f112790898"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text_cleaning'], df['label_num'], test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53866125-3591-4acc-b943-e408cdbbcfc0",
      "metadata": {
        "id": "53866125-3591-4acc-b943-e408cdbbcfc0"
      },
      "source": [
        "Andiamo ora a creare una vettorizzazione TF-IDF della colonna riferita al train e al test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3df9f94-252b-4047-aab5-6d68956d5fc9",
      "metadata": {
        "id": "e3df9f94-252b-4047-aab5-6d68956d5fc9"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Creazione del vettorizzatore TF-IDF e trasformazione dei dati\n",
        "vectorizer = TfidfVectorizer(binary=True)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46e09fcd-0e50-481c-b4f8-e5a164b8deb2",
      "metadata": {
        "id": "46e09fcd-0e50-481c-b4f8-e5a164b8deb2"
      },
      "source": [
        "Adesso possiamo procedere con l'addestramento di un classificatore. Quelli che andremo a mettere a confronto saranno :\n",
        "\n",
        "1. Naive Bayes\n",
        "2. Support Vector Machines (SVM)\n",
        "3. Reti neurali"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31ba48cc-d188-4a2d-9e8d-cd9579a27fed",
      "metadata": {
        "id": "31ba48cc-d188-4a2d-9e8d-cd9579a27fed"
      },
      "source": [
        "### Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3fcb4eb-b411-4f42-b623-f31b5fd6ddf8",
      "metadata": {
        "id": "e3fcb4eb-b411-4f42-b623-f31b5fd6ddf8"
      },
      "source": [
        "Proviamo ad utilizzare il Bernoulli Naive Bayes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "554412c7-fa67-4248-8f5f-d5a0e9ccf7cf",
      "metadata": {
        "id": "554412c7-fa67-4248-8f5f-d5a0e9ccf7cf"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Addestramento del classificatore Bernoulli Naive Bayes\n",
        "clf = BernoulliNB()\n",
        "clf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predizione sui dati di test\n",
        "y_pred = clf.predict(X_test_tfidf)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b39ab0b5-9c3c-49ed-83ef-b19654a7ec33",
      "metadata": {
        "id": "b39ab0b5-9c3c-49ed-83ef-b19654a7ec33"
      },
      "source": [
        "Proviamo a valutare le prestazioni del modello."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e6b3f8d-b041-478f-86f0-64683c997838",
      "metadata": {
        "id": "2e6b3f8d-b041-478f-86f0-64683c997838"
      },
      "outputs": [],
      "source": [
        "# Valutazione delle prestazioni del modello\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cd7167a-2461-49c5-a8ca-41eaebd552f0",
      "metadata": {
        "id": "0cd7167a-2461-49c5-a8ca-41eaebd552f0"
      },
      "source": [
        "### Support Vector Machines (SVM)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "751fd1bd-a436-4a1c-be0b-0eecc40345c8",
      "metadata": {
        "id": "751fd1bd-a436-4a1c-be0b-0eecc40345c8"
      },
      "source": [
        "Andiamo ora a vedere si applica invece il modello SVM al problema di classificazione."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e5f1334-584b-4139-b336-bde075696bd6",
      "metadata": {
        "id": "3e5f1334-584b-4139-b336-bde075696bd6"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svc = SVC()\n",
        "svc.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predizione sui dati di test\n",
        "y_pred = svc.predict(X_test_tfidf)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81dd175d-c730-41df-8e68-e04a817d1670",
      "metadata": {
        "scrolled": true,
        "id": "81dd175d-c730-41df-8e68-e04a817d1670"
      },
      "outputs": [],
      "source": [
        "# Valutazione delle prestazioni del modello\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51f170a7-96eb-4fba-9d4f-53f2249793ff",
      "metadata": {
        "id": "51f170a7-96eb-4fba-9d4f-53f2249793ff"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "dab0ae00-e2fe-4dd0-a96f-96d60eda4fa1",
      "metadata": {
        "id": "dab0ae00-e2fe-4dd0-a96f-96d60eda4fa1"
      },
      "source": [
        "### Reti Neurali"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0953b8d7-fff5-4ffb-b3ec-db0ad123f8c8",
      "metadata": {
        "id": "0953b8d7-fff5-4ffb-b3ec-db0ad123f8c8"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "# Multi-layer Perceptron Classifier (MLP)\n",
        "mlp_clf = MLPClassifier(hidden_layer_sizes=(100,))\n",
        "mlp_clf.fit(X_train_tfidf, y_train)\n",
        "y_pred = mlp_clf.predict(X_test_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a73c8c73-1889-4374-acce-13a91d50918b",
      "metadata": {
        "id": "a73c8c73-1889-4374-acce-13a91d50918b"
      },
      "outputs": [],
      "source": [
        "# Valutazione delle prestazioni del modello\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca2963b6-8e25-41e0-b93e-c754fa347b98",
      "metadata": {
        "id": "ca2963b6-8e25-41e0-b93e-c754fa347b98"
      },
      "source": [
        "Come possiamo vedere sia il modello SVM che a Reti Neurali dimostrano le migliori performance predittive."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "223ead65-18fa-4ae7-aa5b-e11e8eb4a160",
      "metadata": {
        "id": "223ead65-18fa-4ae7-aa5b-e11e8eb4a160"
      },
      "source": [
        "# Individuazione dei Topic principali su SPAM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5e063b9-4ded-4480-9631-31fdbdce2bb1",
      "metadata": {
        "id": "d5e063b9-4ded-4480-9631-31fdbdce2bb1"
      },
      "source": [
        "Come altro task previsto nel progetto andiamo adesso a individuare i Principali Argomenti tra le Email SPAM nel dettaglio andremo a:\n",
        "\n",
        "    Effettuare il topic modeling sulle email SPAM per scoprire i principali temi o argomenti presenti.\n",
        "    Utilizzare tecniche come la Latent Dirichlet Allocation (LDA) o la Non-negative Matrix Factorization (NMF) per l'estrazione degli argomenti.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a4a609c-2529-4606-afc3-5013c7353aba",
      "metadata": {
        "id": "6a4a609c-2529-4606-afc3-5013c7353aba"
      },
      "source": [
        "Quello che faremo sarà dunque l'applicazione dell'algoritmo **Latent Dirichlet Allocation** LDA che permette di individuare l'insieme di argomenti trattati."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "152facf6-0926-467e-9c7a-0980c4d3ad31",
      "metadata": {
        "id": "152facf6-0926-467e-9c7a-0980c4d3ad31"
      },
      "source": [
        "Iniziamo a importarci gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73838eeb-6a56-4275-88c1-32c92decea52",
      "metadata": {
        "id": "73838eeb-6a56-4275-88c1-32c92decea52"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edcaae15-f2d0-4f2b-a235-a1f8f472884c",
      "metadata": {
        "id": "edcaae15-f2d0-4f2b-a235-a1f8f472884c"
      },
      "source": [
        "Ci andiamo a creare il dizionario di tutte le parole contenute nello SPAM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83876ab6-2ac2-4a30-80d1-d82e0dbfcba2",
      "metadata": {
        "id": "83876ab6-2ac2-4a30-80d1-d82e0dbfcba2"
      },
      "source": [
        "Andiamo quindi a tokenizzare il testo utilizzando gensim.corpora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "647247ba-72e6-431e-99bb-af9ce576d83d",
      "metadata": {
        "id": "647247ba-72e6-431e-99bb-af9ce576d83d"
      },
      "outputs": [],
      "source": [
        "def sent_to_words(items):\n",
        "    for item in items:\n",
        "        yield(simple_preprocess(item, deacc=True)) # Viene restituita una lista (con deacc=True elimina la punteggiatura dal testo)\n",
        "\n",
        "\n",
        "df = df[df['label_num']==1] # Vado a filtrarmi solo i record di tipo Spam\n",
        "data_words = list(sent_to_words(df['text_cleaning'])) # Tokenizziamo il testo"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc1bbd5b-095e-4476-9f57-d392c966c33a",
      "metadata": {
        "id": "bc1bbd5b-095e-4476-9f57-d392c966c33a"
      },
      "source": [
        "Vediamo quale è il risultato della Tokenizzazione per la prima frase del dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "472835e2-2505-4966-b92c-10d699933137",
      "metadata": {
        "id": "472835e2-2505-4966-b92c-10d699933137"
      },
      "outputs": [],
      "source": [
        "data_words[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e25b22ba-a74a-4f07-8805-684a1fdc4362",
      "metadata": {
        "id": "e25b22ba-a74a-4f07-8805-684a1fdc4362"
      },
      "source": [
        "Come abbiamo potuto vedere, abbiamo tokenizzato le frasi del nostro documento ora per poter dare in pasto al modello LDA occorre andare a vettorizzare. Come prima cosa prima di processare la vettorizzazione andiamo a definirci il nostro dizionario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "caf9e46b-3cb7-4cfd-83a3-571ec4077b33",
      "metadata": {
        "id": "caf9e46b-3cb7-4cfd-83a3-571ec4077b33"
      },
      "outputs": [],
      "source": [
        "id2word = corpora.Dictionary(data_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8e526e6-f3c1-4cd2-a019-e6e9f2ab1f54",
      "metadata": {
        "id": "b8e526e6-f3c1-4cd2-a019-e6e9f2ab1f54"
      },
      "source": [
        "Andiamo adesso a vettorizzarlo il che vuol dire andare a sostituire le parole in vettori numerici:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a7ab59b-b1e6-48c5-a7f0-2c7b17583da2",
      "metadata": {
        "id": "2a7ab59b-b1e6-48c5-a7f0-2c7b17583da2"
      },
      "outputs": [],
      "source": [
        "corpus = [id2word.doc2bow(text) for text in data_words] # Il metodo doc2bow effettua il bag of word tramite il \"Count Vectorizer\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91c4f87d-8d26-404a-b405-a86c2407037c",
      "metadata": {
        "id": "91c4f87d-8d26-404a-b405-a86c2407037c"
      },
      "outputs": [],
      "source": [
        "corpus[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef52f81c-8926-40d8-ba03-3b17056dea2a",
      "metadata": {
        "id": "ef52f81c-8926-40d8-ba03-3b17056dea2a"
      },
      "source": [
        "Come possiamo vedere abbiamo la vettorizzazione pronta possiamo quindi procedere a impostare il modello LDA:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff237303-8e0e-402b-aa5d-fbcf88059b8a",
      "metadata": {
        "id": "ff237303-8e0e-402b-aa5d-fbcf88059b8a"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "import gensim\n",
        "\n",
        "# Inizializziamo con 10 i topics che vogliamo nel nostro modello - qui ad esempio mettiamo 10 TOPICS\n",
        "num_topics = 3\n",
        "\n",
        "# Creo il modello LDA utilizzando LdaMulticore, che è efficiente per il calcolo su più core della CPU\n",
        "lda_model = gensim.models.LdaMulticore(\n",
        "    corpus=corpus,  # 'corpus' è una collezione di documenti testuali in forma vettoriale che abbiamo processato in BoW e CountVectorizer\n",
        "    id2word=id2word,  # 'id2word' è un dizionario che mappa gli ID numerici delle parole ai loro testi\n",
        "    num_topics=num_topics,  # Numero di topic desiderati nel modello\n",
        "    passes=1,  # Numero di passaggi\n",
        "    chunksize=100,  # Dimensione dei chunk per migliorare l'efficienza\n",
        "    workers=4,  # Numero di core da utilizzare\n",
        "    alpha='asymmetric',  # Ottimizzazione automatica di alpha\n",
        "    eta='auto'  # Ottimizzazione automatica di eta\n",
        ")\n",
        "\n",
        "# Stampa il primo topic. È necessario specificare l'indice del topic da stampare.\n",
        "pprint(lda_model.print_topics(num_topics=10, num_words=10))\n",
        "\n",
        "# Applica il modello LDA al corpus per ottenere la distribuzione dei topic per ogni documento.\n",
        "doc_lda = lda_model[corpus]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7495504a-0ddc-4f37-9aef-ad7b39532ce1",
      "metadata": {
        "id": "7495504a-0ddc-4f37-9aef-ad7b39532ce1"
      },
      "source": [
        "Ottenuto il modello LDA andiamo adesso a mostrare le parole chiave per ciascun topic:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd40a0d4-9427-456e-b0d4-ab3445ba9957",
      "metadata": {
        "id": "fd40a0d4-9427-456e-b0d4-ab3445ba9957"
      },
      "outputs": [],
      "source": [
        "topics = lda_model.print_topics(num_topics=num_topics, num_words=10)\n",
        "print(\"Topics:\")\n",
        "pprint(topics)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e4533c7-9aac-479a-8a07-f42984c4cc6f",
      "metadata": {
        "id": "1e4533c7-9aac-479a-8a07-f42984c4cc6f"
      },
      "source": [
        "In questo modo abbiamo una rappresentazione delle 10 parole piu rappresentative dei 10 topic individuati all'interno del dataset di Spam."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19fc486b-7e21-481b-8210-02cc055b5864",
      "metadata": {
        "id": "19fc486b-7e21-481b-8210-02cc055b5864"
      },
      "source": [
        "# Calcolo distanza semantica tra i topics ottenuti"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9814b159-c09a-4147-b417-0e4f94935bb3",
      "metadata": {
        "id": "9814b159-c09a-4147-b417-0e4f94935bb3"
      },
      "source": [
        "Una volta definiti i topics andiamo dunque a verificare quale è la distanza semantica tra i topics ottenuti andando quindi ad estrarre le distribuzioni di probabilità dei topic e calcolandovi la distsanza coseno :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8f0452a-6ad9-47b8-9db4-2425a45f45ea",
      "metadata": {
        "id": "f8f0452a-6ad9-47b8-9db4-2425a45f45ea"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Estrazione delle distribuzioni di probabilità dei topic\n",
        "topic_word_distributions = lda_model.get_topics()\n",
        "\n",
        "# Calcolo della distanza coseno tra tutte le coppie di topic\n",
        "distance_matrix = cosine_distances(topic_word_distributions)\n",
        "\n",
        "# Visualizzazione della matrice delle distanze\n",
        "print(\"Matrice delle distanze coseno tra i topic:\")\n",
        "print(distance_matrix)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76e5088a-2bb9-48fb-99d1-02176b37f015",
      "metadata": {
        "id": "76e5088a-2bb9-48fb-99d1-02176b37f015"
      },
      "source": [
        "# Effettuare il Named Entity Recognition sul nome delle Organizzazioni"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c34a2b62-021e-4e32-af35-4c725195909d",
      "metadata": {
        "id": "c34a2b62-021e-4e32-af35-4c725195909d"
      },
      "source": [
        "Tra le mail non Spam del dataset andiamo a individuare tutti i nomi delle Organizzazioni in esso contenute."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4015d3d0-1d0b-4ca9-bb05-493232e02778",
      "metadata": {
        "id": "4015d3d0-1d0b-4ca9-bb05-493232e02778"
      },
      "source": [
        "Prima di tutto vado a caricarmi il modello"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e03e910-0119-4385-aa42-711200869bdb",
      "metadata": {
        "id": "0e03e910-0119-4385-aa42-711200869bdb"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm') #Mi import spacy e mi carico il modello"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5647b1ef-d9db-4575-907f-46ea955be8bf",
      "metadata": {
        "id": "5647b1ef-d9db-4575-907f-46ea955be8bf"
      },
      "source": [
        "Andiamo ora a filtrarci i testi NON SPAM:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dc75758-faaa-4f42-89f7-de7868ae388f",
      "metadata": {
        "id": "4dc75758-faaa-4f42-89f7-de7868ae388f"
      },
      "outputs": [],
      "source": [
        "df_no_spam = df[['label_num']==0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa25c749-e43e-474f-89ef-02acfd6ffea6",
      "metadata": {
        "id": "aa25c749-e43e-474f-89ef-02acfd6ffea6"
      },
      "outputs": [],
      "source": [
        "sentences_no_spam = df['text_cleaning']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b5f0443-9985-41d0-9b02-53e8f6a0af06",
      "metadata": {
        "id": "7b5f0443-9985-41d0-9b02-53e8f6a0af06"
      },
      "source": [
        "Partendo da esse applicheremo il Named Entity Recognition (NER) sulle organizzazioni (ORG):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c780e51-e3b2-49c3-ad92-c25d42fee986",
      "metadata": {
        "id": "2c780e51-e3b2-49c3-ad92-c25d42fee986"
      },
      "outputs": [],
      "source": [
        "\n",
        "list_org = []\n",
        "\n",
        "for elem in sentences_no_spam:\n",
        "    doc = nlp(elem)\n",
        "    for token in doc:\n",
        "        if token.ent_type == 'ORG':\n",
        "            list_org.append(token)\n",
        "\n",
        "\n",
        "print(token)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}